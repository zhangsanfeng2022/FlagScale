From 3415f3998f170a58411f06c5e83e0240361b51d5 Mon Sep 17 00:00:00 2001
From: zhangsanfeng2022 <ludehui2022@163.com>
Date: Thu, 17 Oct 2024 21:10:06 +0800
Subject: [PATCH] [kunlunxin] llava1.5 7b fix.

---
 examples/llava/conf/config.yaml               | 30 ++++++++++++++++---
 .../llava/conf/train/train_llava1.5_7b.yaml   |  4 ++-
 megatron/megatron/training/checkpointing.py   |  9 +++---
 3 files changed, 33 insertions(+), 10 deletions(-)

diff --git a/examples/llava/conf/config.yaml b/examples/llava/conf/config.yaml
index e7b327ee..c46241b8 100644
--- a/examples/llava/conf/config.yaml
+++ b/examples/llava/conf/config.yaml
@@ -15,13 +15,35 @@ experiment:
     nproc_per_node: 8
     hostfile: <xxx>
   envs:
-    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7 
+    ALLGATHER_ASYNC: false
+    ALLREDUCE_ASYNC: false
+    ALLREDUCE_FUSION: 0
+    BKCL_CCIX_BUFFER_GM: 1
+    BKCL_CCIX_RING: 1
+    BKCL_ENABLE_XDR: 1
+    BKCL_FLAT_RING: 1
+    BKCL_KL3_TURBO_MODE: 1
+    BKCL_RDMA_FORCE_TREE: 1
+    BKCL_RDMA_NICS: ens11np0,ens11np0,ens13np0,ens13np0,ens15np0,ens15np0,ens17np0,ens17np0
+    BKCL_RDMA_PROXY_DISABLE: 1
+    BKCL_RING_BUFFER_GM: 1
+    BKCL_TIMEOUT: 360000
+    BKCL_TRANS_UNSUPPORTED_DATATYPE: 1
+    BKCL_TREE_THRESHOLD: 1
+    BKCL_XLINK_C2C: 1
+    BKCL_XLINK_D2D: 0
+    BKCL_XLINK_ETH: 0
+    CUDART_DUMMY_REGISTER: 1
     CUDA_DEVICE_MAX_CONNECTIONS: 1
-    NVTE_APPLY_QK_LAYER_SCALING: 0
+    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
+    FAST_SWIGLU_ENABLE: 1
     NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
-
+    NVTE_APPLY_QK_LAYER_SCALING: 0
+    USE_FAST_BF16_FC: true
+    USE_L3: 1
+    XDNN_USE_FAST_SWISH: true
+    XPU_ZEBU_MODE: 1
 action: run 
-
 hydra: 
   run:
     dir: ${experiment.exp_dir}/hydra 
diff --git a/examples/llava/conf/train/train_llava1.5_7b.yaml b/examples/llava/conf/train/train_llava1.5_7b.yaml
index 040b73ca..c1cfde55 100644
--- a/examples/llava/conf/train/train_llava1.5_7b.yaml
+++ b/examples/llava/conf/train/train_llava1.5_7b.yaml
@@ -7,7 +7,9 @@ system:
   use_mcore_models: True
   transformer_impl: transformer_engine
   precision:
-    bf16: True
+    fp16: True
+    initial_loss_scale: 512
+    min_loss_scale: 1.0
     attention_softmax_in_fp32: True
   logging:
     log_interval: 1
diff --git a/megatron/megatron/training/checkpointing.py b/megatron/megatron/training/checkpointing.py
index 01425f36..459b76db 100644
--- a/megatron/megatron/training/checkpointing.py
+++ b/megatron/megatron/training/checkpointing.py
@@ -231,7 +231,7 @@ def read_metadata(tracker_filename):
                 print_rank_0('ERROR: Invalid metadata file {}. Exiting'.format(
                     tracker_filename))
                 sys.exit()
-    # TODO: we use iteration 0 to load checkpoint from other framework.  
+    # TODO: we use iteration 0 to load checkpoint from other framework.
     # We should remove this after we have a better way to load checkpoint from other framework.
     assert iteration >= 0 or release, 'error parsing metadata file {}'.format(
         tracker_filename)
@@ -530,8 +530,7 @@ def save_dataloader_state(train_iterator, iteration, dataloader_save_path):
 
     torch.distributed.barrier(group=mpu.get_data_parallel_group())
 
-    if mpu.get_data_parallel_rank() == 0:
-        ensure_directory_exists(data_state_save_path)
+    ensure_directory_exists(data_state_save_path)
 
     torch.distributed.barrier(group=mpu.get_data_parallel_group())
 
@@ -1109,7 +1108,7 @@ def load_checkpoint(model, optimizer, opt_param_scheduler, load_arg='load', stri
         if (args.fp16 or args.bf16) and optimizer is not None \
             and not args.finetune_with_optim:
             optimizer.reload_model_params()
-    
+
     if args.finetune_with_optim:
         try:
             # Load state dict.
@@ -1128,7 +1127,7 @@ def load_checkpoint(model, optimizer, opt_param_scheduler, load_arg='load', stri
                         model_checkpoint_name)
                 optimizer.load_parameter_state(optim_checkpoint_name)
             # Reset iteration to 0 after loading optimizer
-            # after making use of the iteration returned by read_metadata 
+            # after making use of the iteration returned by read_metadata
             iteration = 0
 
         except KeyError:
-- 
2.47.0
